{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2781d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "what_to_do = {'0. An end-to-end Scikit-Learn workflow',\n",
    " '1. Getting the data ready',\n",
    " '2. Choose the right estimator/algorithm for our problems',\n",
    " '3. Fit the model/algorithm and use it to make predictions on our data',\n",
    " '4. Evaluating a model',\n",
    " '5. Improve a model',\n",
    " '6. Save and load a trained model',\n",
    " '7. Putting it all together!'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8cf83d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 19:25:44.753908: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-02 19:25:44.933525: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-02 19:25:48.933755: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ec7d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431</td>\n",
       "      <td>4</td>\n",
       "      <td>15323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714</td>\n",
       "      <td>5</td>\n",
       "      <td>19943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714</td>\n",
       "      <td>4</td>\n",
       "      <td>28343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365</td>\n",
       "      <td>4</td>\n",
       "      <td>13434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577</td>\n",
       "      <td>3</td>\n",
       "      <td>14043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820</td>\n",
       "      <td>4</td>\n",
       "      <td>32042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>White</td>\n",
       "      <td>155144</td>\n",
       "      <td>3</td>\n",
       "      <td>5716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604</td>\n",
       "      <td>4</td>\n",
       "      <td>31570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883</td>\n",
       "      <td>4</td>\n",
       "      <td>4001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360</td>\n",
       "      <td>4</td>\n",
       "      <td>12732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors  Price\n",
       "0     Honda  White          35431      4  15323\n",
       "1       BMW   Blue         192714      5  19943\n",
       "2     Honda  White          84714      4  28343\n",
       "3    Toyota  White         154365      4  13434\n",
       "4    Nissan   Blue         181577      3  14043\n",
       "..      ...    ...            ...    ...    ...\n",
       "995  Toyota  Black          35820      4  32042\n",
       "996  Nissan  White         155144      3   5716\n",
       "997  Nissan   Blue          66604      4  31570\n",
       "998   Honda  White         215883      4   4001\n",
       "999  Toyota   Blue         248360      4  12732\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales  = pd.read_csv(\"https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/master/data/car-sales-extended.csv\")\n",
    "car_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26e27c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales.drop(\"Price\", axis=1)\n",
    "Y = car_sales[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7399a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"Make\", \"Colour\"]\n",
    "numeric_cols = [\"Odometer (KM)\", \"Doors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "707303d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import StringLookup, Normalization\n",
    "\n",
    "categorical_cols = [\"Make\", \"Colour\"]\n",
    "numeric_cols = [\"Odometer (KM)\", \"Doors\"]\n",
    "\n",
    "# String lookup layers\n",
    "make_lookup = StringLookup(output_mode=\"int\")\n",
    "color_lookup = StringLookup(output_mode=\"int\")\n",
    "\n",
    "make_lookup.adapt(X[\"Make\"])\n",
    "color_lookup.adapt(X[\"Colour\"])\n",
    "\n",
    "# Normalization layer — FIX\n",
    "normalizer = Normalization()\n",
    "normalizer.adapt(X[numeric_cols].to_numpy())  # use X not x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae809e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(x):\n",
    "    make = tf.cast(make_lookup(x[\"Make\"]), tf.float32)\n",
    "    color = tf.cast(color_lookup(x[\"Colour\"]), tf.float32)\n",
    "\n",
    "    # Combine numeric columns in a 1D tensor\n",
    "    numeric = tf.stack([\n",
    "        tf.cast(x[\"Odometer (KM)\"], tf.float32),\n",
    "        tf.cast(x[\"Doors\"], tf.float32)\n",
    "    ])\n",
    "    \n",
    "    # Normalize numeric features\n",
    "    numeric = normalizer(tf.expand_dims(numeric, axis=0))\n",
    "    numeric = tf.squeeze(numeric)\n",
    "\n",
    "    # Combine all features into one tensor\n",
    "    return tf.concat([make[tf.newaxis], color[tf.newaxis], numeric], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98116e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = tf.data.Dataset.from_tensor_slices((dict(X), Y.values))\n",
    "full_data = full_data.shuffle(buffer_size=len(car_sales), seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1067ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = full_data.map(lambda x, y: (preprocess_features(x), tf.cast(y, tf.float32)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b64db01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(car_sales))\n",
    "train_data = full_data.take(train_size).batch(32)\n",
    "test_data = full_data.skip(train_size).batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c15d6378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 19:49:47.585753: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((tf.Tensor(3.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(14986.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((tf.Tensor(1.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(24834.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((tf.Tensor(4.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(50868.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((tf.Tensor(1.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(15960.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((tf.Tensor(1.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(14698.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>((tf.Tensor(2.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(14202.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>((tf.Tensor(1.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(17258.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>((tf.Tensor(1.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(11036.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>((tf.Tensor(1.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(6121.0, shape=(), dtype=float32), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>((tf.Tensor(2.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(14431.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>((tf.Tensor(4.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(31296.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>((tf.Tensor(3.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(5595.0, shape=(), dtype=float32), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>((tf.Tensor(3.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(23438.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>((tf.Tensor(4.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(25763.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>((tf.Tensor(3.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(15673.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>((tf.Tensor(2.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(23728.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>((tf.Tensor(2.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(6690.0, shape=(), dtype=float32), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>((tf.Tensor(3.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(7252.0, shape=(), dtype=float32), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>((tf.Tensor(2.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(7076.0, shape=(), dtype=float32), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>((tf.Tensor(1.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(20424.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>((tf.Tensor(3.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(23945.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>((tf.Tensor(3.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(13474.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>((tf.Tensor(1.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(17284.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>((tf.Tensor(3.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(31536.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>((tf.Tensor(3.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(13005.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0  \\\n",
       "0   ((tf.Tensor(3.0, shape=(), dtype=float32), tf....   \n",
       "1   ((tf.Tensor(1.0, shape=(), dtype=float32), tf....   \n",
       "2   ((tf.Tensor(4.0, shape=(), dtype=float32), tf....   \n",
       "3   ((tf.Tensor(1.0, shape=(), dtype=float32), tf....   \n",
       "4   ((tf.Tensor(1.0, shape=(), dtype=float32), tf....   \n",
       "5   ((tf.Tensor(2.0, shape=(), dtype=float32), tf....   \n",
       "6   ((tf.Tensor(1.0, shape=(), dtype=float32), tf....   \n",
       "7   ((tf.Tensor(1.0, shape=(), dtype=float32), tf....   \n",
       "8   ((tf.Tensor(1.0, shape=(), dtype=float32), tf....   \n",
       "9   ((tf.Tensor(2.0, shape=(), dtype=float32), tf....   \n",
       "10  ((tf.Tensor(4.0, shape=(), dtype=float32), tf....   \n",
       "11  ((tf.Tensor(3.0, shape=(), dtype=float32), tf....   \n",
       "12  ((tf.Tensor(3.0, shape=(), dtype=float32), tf....   \n",
       "13  ((tf.Tensor(4.0, shape=(), dtype=float32), tf....   \n",
       "14  ((tf.Tensor(3.0, shape=(), dtype=float32), tf....   \n",
       "15  ((tf.Tensor(2.0, shape=(), dtype=float32), tf....   \n",
       "16  ((tf.Tensor(2.0, shape=(), dtype=float32), tf....   \n",
       "17  ((tf.Tensor(3.0, shape=(), dtype=float32), tf....   \n",
       "18  ((tf.Tensor(2.0, shape=(), dtype=float32), tf....   \n",
       "19  ((tf.Tensor(1.0, shape=(), dtype=float32), tf....   \n",
       "20  ((tf.Tensor(3.0, shape=(), dtype=float32), tf....   \n",
       "21  ((tf.Tensor(3.0, shape=(), dtype=float32), tf....   \n",
       "22  ((tf.Tensor(1.0, shape=(), dtype=float32), tf....   \n",
       "23  ((tf.Tensor(3.0, shape=(), dtype=float32), tf....   \n",
       "24  ((tf.Tensor(3.0, shape=(), dtype=float32), tf....   \n",
       "\n",
       "                                                    1  \n",
       "0   (tf.Tensor(14986.0, shape=(), dtype=float32), ...  \n",
       "1   (tf.Tensor(24834.0, shape=(), dtype=float32), ...  \n",
       "2   (tf.Tensor(50868.0, shape=(), dtype=float32), ...  \n",
       "3   (tf.Tensor(15960.0, shape=(), dtype=float32), ...  \n",
       "4   (tf.Tensor(14698.0, shape=(), dtype=float32), ...  \n",
       "5   (tf.Tensor(14202.0, shape=(), dtype=float32), ...  \n",
       "6   (tf.Tensor(17258.0, shape=(), dtype=float32), ...  \n",
       "7   (tf.Tensor(11036.0, shape=(), dtype=float32), ...  \n",
       "8   (tf.Tensor(6121.0, shape=(), dtype=float32), t...  \n",
       "9   (tf.Tensor(14431.0, shape=(), dtype=float32), ...  \n",
       "10  (tf.Tensor(31296.0, shape=(), dtype=float32), ...  \n",
       "11  (tf.Tensor(5595.0, shape=(), dtype=float32), t...  \n",
       "12  (tf.Tensor(23438.0, shape=(), dtype=float32), ...  \n",
       "13  (tf.Tensor(25763.0, shape=(), dtype=float32), ...  \n",
       "14  (tf.Tensor(15673.0, shape=(), dtype=float32), ...  \n",
       "15  (tf.Tensor(23728.0, shape=(), dtype=float32), ...  \n",
       "16  (tf.Tensor(6690.0, shape=(), dtype=float32), t...  \n",
       "17  (tf.Tensor(7252.0, shape=(), dtype=float32), t...  \n",
       "18  (tf.Tensor(7076.0, shape=(), dtype=float32), t...  \n",
       "19  (tf.Tensor(20424.0, shape=(), dtype=float32), ...  \n",
       "20  (tf.Tensor(23945.0, shape=(), dtype=float32), ...  \n",
       "21  (tf.Tensor(13474.0, shape=(), dtype=float32), ...  \n",
       "22  (tf.Tensor(17284.0, shape=(), dtype=float32), ...  \n",
       "23  (tf.Tensor(31536.0, shape=(), dtype=float32), ...  \n",
       "24  (tf.Tensor(13005.0, shape=(), dtype=float32), ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b56bc4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((tf.Tensor(2.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(15297.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((tf.Tensor(1.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(30191.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((tf.Tensor(1.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(9918.0, shape=(), dtype=float32), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((tf.Tensor(3.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(16730.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((tf.Tensor(1.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(8834.0, shape=(), dtype=float32), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>((tf.Tensor(2.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(26078.0, shape=(), dtype=float32), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>((tf.Tensor(1.0, shape=(), dtype=float32), tf....</td>\n",
       "      <td>(tf.Tensor(5285.0, shape=(), dtype=float32), t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  ((tf.Tensor(2.0, shape=(), dtype=float32), tf....   \n",
       "1  ((tf.Tensor(1.0, shape=(), dtype=float32), tf....   \n",
       "2  ((tf.Tensor(1.0, shape=(), dtype=float32), tf....   \n",
       "3  ((tf.Tensor(3.0, shape=(), dtype=float32), tf....   \n",
       "4  ((tf.Tensor(1.0, shape=(), dtype=float32), tf....   \n",
       "5  ((tf.Tensor(2.0, shape=(), dtype=float32), tf....   \n",
       "6  ((tf.Tensor(1.0, shape=(), dtype=float32), tf....   \n",
       "\n",
       "                                                   1  \n",
       "0  (tf.Tensor(15297.0, shape=(), dtype=float32), ...  \n",
       "1  (tf.Tensor(30191.0, shape=(), dtype=float32), ...  \n",
       "2  (tf.Tensor(9918.0, shape=(), dtype=float32), t...  \n",
       "3  (tf.Tensor(16730.0, shape=(), dtype=float32), ...  \n",
       "4  (tf.Tensor(8834.0, shape=(), dtype=float32), t...  \n",
       "5  (tf.Tensor(26078.0, shape=(), dtype=float32), ...  \n",
       "6  (tf.Tensor(5285.0, shape=(), dtype=float32), t...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9c34054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 19:53:56.423761: I external/local_xla/xla/service/service.cc:163] XLA service 0x760d8806aa00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-02 19:53:56.423823: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-11-02 19:53:56.510051: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-02 19:53:57.037095: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91400\n",
      "2025-11-02 19:53:57.090639: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-11-02 19:53:57.090757: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-11-02 19:53:57.090878: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-11-02 19:54:00.972468: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_126', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "2025-11-02 19:54:01.349340: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_126', 100 bytes spill stores, 100 bytes spill loads\n",
      "\n",
      "2025-11-02 19:54:02.061587: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_304', 468 bytes spill stores, 468 bytes spill loads\n",
      "\n",
      "2025-11-02 19:54:03.119118: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_304', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-11-02 19:54:04.114623: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_304', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 16077.2967 - mae: 16077.2967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762093446.385094    8273 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 16114.7373 - mae: 16114.7373\n",
      "Epoch 2/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 16195.0479 - mae: 16195.0479\n",
      "Epoch 3/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 16180.9150 - mae: 16180.9150\n",
      "Epoch 4/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 15963.0283 - mae: 15963.0283\n",
      "Epoch 5/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 15493.5146 - mae: 15493.5146\n",
      "Epoch 6/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 15604.2695 - mae: 15604.2695\n",
      "Epoch 7/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 15113.9873 - mae: 15113.9873\n",
      "Epoch 8/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 14272.2695 - mae: 14272.2695\n",
      "Epoch 9/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 13472.8984 - mae: 13472.8984\n",
      "Epoch 10/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 12511.9404 - mae: 12511.9404\n",
      "Epoch 11/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 10823.7773 - mae: 10823.7773\n",
      "Epoch 12/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 10154.8203 - mae: 10154.8203\n",
      "Epoch 13/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8711.8379 - mae: 8711.8379\n",
      "Epoch 14/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7872.9058 - mae: 7872.9058\n",
      "Epoch 15/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7653.3579 - mae: 7653.3579\n",
      "Epoch 16/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7221.4136 - mae: 7221.4136\n",
      "Epoch 17/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7148.8867 - mae: 7148.8867\n",
      "Epoch 18/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7140.3594 - mae: 7140.3594\n",
      "Epoch 19/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7045.6250 - mae: 7045.6250\n",
      "Epoch 20/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7052.6357 - mae: 7052.6357\n",
      "Epoch 21/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6954.8242 - mae: 6954.8242\n",
      "Epoch 22/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6969.6411 - mae: 6969.6411\n",
      "Epoch 23/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6843.8950 - mae: 6843.8950\n",
      "Epoch 24/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6877.1323 - mae: 6877.1323\n",
      "Epoch 25/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6984.3013 - mae: 6984.3013\n",
      "Epoch 26/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6641.2500 - mae: 6641.2500\n",
      "Epoch 27/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6680.1123 - mae: 6680.1123\n",
      "Epoch 28/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6864.7871 - mae: 6864.7871\n",
      "Epoch 29/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6589.4067 - mae: 6589.4067\n",
      "Epoch 30/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6682.5610 - mae: 6682.5610\n",
      "Epoch 31/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6704.4438 - mae: 6704.4438\n",
      "Epoch 32/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6473.1489 - mae: 6473.1489\n",
      "Epoch 33/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6645.0566 - mae: 6645.0566\n",
      "Epoch 34/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6557.5801 - mae: 6557.5801\n",
      "Epoch 35/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6590.0767 - mae: 6590.0767\n",
      "Epoch 36/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6511.2900 - mae: 6511.2900\n",
      "Epoch 37/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6475.3574 - mae: 6475.3574\n",
      "Epoch 38/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6589.1367 - mae: 6589.1367\n",
      "Epoch 39/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6620.0049 - mae: 6620.0049\n",
      "Epoch 40/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6558.5464 - mae: 6558.5464\n",
      "Epoch 41/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6392.5552 - mae: 6392.5552\n",
      "Epoch 42/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6617.2944 - mae: 6617.2944\n",
      "Epoch 43/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6553.3213 - mae: 6553.3213\n",
      "Epoch 44/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6423.3101 - mae: 6423.3101\n",
      "Epoch 45/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6553.0508 - mae: 6553.0508\n",
      "Epoch 46/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6430.8076 - mae: 6430.8076\n",
      "Epoch 47/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6499.7808 - mae: 6499.7808\n",
      "Epoch 48/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6335.9023 - mae: 6335.9023\n",
      "Epoch 49/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6464.8813 - mae: 6464.8813\n",
      "Epoch 50/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6288.5063 - mae: 6288.5063\n",
      "Epoch 51/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6303.5640 - mae: 6303.5640\n",
      "Epoch 52/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6202.1934 - mae: 6202.1934\n",
      "Epoch 53/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6377.9126 - mae: 6377.9126\n",
      "Epoch 54/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6371.4717 - mae: 6371.4717\n",
      "Epoch 55/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6421.1006 - mae: 6421.1006\n",
      "Epoch 56/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6522.0752 - mae: 6522.0752\n",
      "Epoch 57/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6324.4131 - mae: 6324.4131\n",
      "Epoch 58/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6220.3545 - mae: 6220.3545\n",
      "Epoch 59/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6200.5405 - mae: 6200.5405\n",
      "Epoch 60/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6322.1313 - mae: 6322.1313\n",
      "Epoch 61/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6209.0620 - mae: 6209.0620\n",
      "Epoch 62/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6306.9839 - mae: 6306.9839\n",
      "Epoch 63/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6304.6543 - mae: 6304.6543\n",
      "Epoch 64/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6241.1870 - mae: 6241.1870\n",
      "Epoch 65/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6255.1895 - mae: 6255.1895\n",
      "Epoch 66/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6194.1445 - mae: 6194.1445\n",
      "Epoch 67/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6308.8525 - mae: 6308.8525\n",
      "Epoch 68/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6378.8086 - mae: 6378.8086\n",
      "Epoch 69/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6259.6724 - mae: 6259.6724\n",
      "Epoch 70/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6266.2227 - mae: 6266.2227\n",
      "Epoch 71/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6252.4575 - mae: 6252.4575\n",
      "Epoch 72/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6122.5820 - mae: 6122.5820\n",
      "Epoch 73/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6213.4775 - mae: 6213.4775\n",
      "Epoch 74/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6190.6030 - mae: 6190.6030\n",
      "Epoch 75/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6177.5449 - mae: 6177.5449\n",
      "Epoch 76/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6246.8477 - mae: 6246.8477\n",
      "Epoch 77/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6344.9893 - mae: 6344.9893\n",
      "Epoch 78/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6180.6177 - mae: 6180.6177\n",
      "Epoch 79/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6208.9863 - mae: 6208.9863\n",
      "Epoch 80/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6270.4526 - mae: 6270.4526\n",
      "Epoch 81/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6279.4263 - mae: 6279.4263\n",
      "Epoch 82/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6195.8369 - mae: 6195.8369\n",
      "Epoch 83/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6128.4175 - mae: 6128.4175\n",
      "Epoch 84/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6212.8223 - mae: 6212.8223\n",
      "Epoch 85/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6343.5107 - mae: 6343.5107\n",
      "Epoch 86/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6130.1309 - mae: 6130.1309\n",
      "Epoch 87/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6188.5693 - mae: 6188.5693\n",
      "Epoch 88/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6237.0117 - mae: 6237.0117\n",
      "Epoch 89/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6288.2505 - mae: 6288.2505\n",
      "Epoch 90/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6089.8013 - mae: 6089.8013\n",
      "Epoch 91/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6109.6646 - mae: 6109.6646\n",
      "Epoch 92/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6264.7056 - mae: 6264.7056\n",
      "Epoch 93/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6061.6763 - mae: 6061.6763\n",
      "Epoch 94/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6195.5552 - mae: 6195.5552\n",
      "Epoch 95/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6049.2202 - mae: 6049.2202\n",
      "Epoch 96/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6094.0410 - mae: 6094.0410\n",
      "Epoch 97/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6146.4292 - mae: 6146.4292\n",
      "Epoch 98/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6027.8887 - mae: 6027.8887\n",
      "Epoch 99/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6087.1992 - mae: 6087.1992\n",
      "Epoch 100/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6155.6367 - mae: 6155.6367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x760db41c9550>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets refit the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "model.fit(train_data, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb98d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
